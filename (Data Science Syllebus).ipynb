{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc301cba-1ad0-4aa4-89ea-2acab7976360",
   "metadata": {},
   "source": [
    "# All Timestam"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f7c3039-eef0-4a34-a0f1-166142453267",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "2:37 Population and Sample Data\n",
    "6:00 STATISTICS ( Descriptive & Inferential )\n",
    "16:59 Measure of central Tendency\n",
    "43:31 Measures of Variability\n",
    "1:15:05 Percentage, Percentiles and Quartiles\n",
    "1:38:55 Measures of Shapes\n",
    "1:56:46 Probability\n",
    "2:09:45 Probability Distribution & Functions\n",
    "2:26:55 Normal Distribution\n",
    "2:31:18 Covariance and Correlation\n",
    "2:53:32 Central Limit Theorem\n",
    "3:11:04 Hypothesis Testing\n",
    "3:25:05 Hypothesis Testing PRACTICAL\n",
    "3:39:51 Z TEST & T TEST PART-1\n",
    "4:15:35 Z TEST & T TEST PART-2\n",
    "4:51:36 CHI SQUARE TEST\n",
    "5:16:06 What is MACHINE LEARNING\n",
    "5:31:28 COMPLETE ROADMAP TO LEARN MACHINE LEARNING\n",
    "5:40:24 Types of Variables in MACHINE LEARNING\n",
    "5:52:27 DATA CLEANING\n",
    "5:58:41 What is MISSING VALUES & How to Find it\n",
    "6:19:39 HANDLING MISSING VALUES ( DROPPING )\n",
    "6:29:13 HANDLING MISSING VALUES ( IMPUTING CATEGORY DATA )\n",
    "6:47:56 ONE HOT ENCODING & DUMMY VARIABLES\n",
    "7:03:16 LABEL ENCODING\n",
    "7:12:05 ORDINAL ENCODING\n",
    "7:26:03 OUTLIER\n",
    "7:38:31 OUTLIER REMOVAL using IQR\n",
    "7:51:26 OUTLIER REMOVAL using Z-SCORE\n",
    "8:10:26 FEATURE SCALING ( STANDARDIZATION )\n",
    "8:30:30 FEATURE SCALING ( NORMALIZATION )\n",
    "8:41:07 HANDLING DUPLICATE DATA\n",
    "8:52:57 REPLACE & DATA TYPE CHANGE\n",
    "9:01:49 FUNCTION TRANSFORMER\n",
    "9:19:29 FEATURE SELECTION TECHNIQUES\n",
    "9:22:43 \tFORWARD ELIMINATION\n",
    "9:26:45 \tBACKWARD ELIMINATION\n",
    "9:33:54 TRAIN-TEST SPLIT DATASET\n",
    "9:44:56 REGRESSION ANALYSIS\n",
    "9:49:02 LINEAR REGRESSION ALGORITHM ( SIMPLE LINEAR )\n",
    "9:59:25 LINEAR REGRESSION ALGORITHM ( SIMPLE LINEAR ) PRACTICAL\n",
    "10:25:27 MULTIPLE LINEAR REGRESSION\n",
    "10:46:11 POLYNOMIAL REGRESSION\n",
    "11:06:55 What is COST FUNCTION\n",
    "1:11:28 TYPES of COST FUNCTION\n",
    "11:13:26 REGRESSION COST FUNCTION\n",
    "11:15:56 MEAN SQUARED ERROR\n",
    "11:23:18 MEAN ABSOLUTE ERROR\n",
    "11:27:58 ROOT MEAN SQUARED ERROR\n",
    "11:28:45 Best Fit Line ( How to find best fit line )\n",
    "11:42:55 Regularization\n",
    "                 L1 ( Lasso Regularization )\n",
    "                 L2 ( Ridge Regularization )\n",
    "11:45:46 L1 or Lasso Regularization Technique\n",
    "11:50:35 L2 or Ridge Regularization Technique\n",
    "11:53:59 L1 and L2 Regularization PRACTICAL\n",
    "12:16:17 Classification Algorithm\n",
    "12:26:15 Logistic Regression ( Binary Classification ) ( Single Input ) PRACTICAL\n",
    "12:47:37 Logistic Regression ( Binary Classification ) ( Multiple Input ) PRACTICAL\n",
    "13:00:09 Logistic Regression ( Binary Classification ) ( Polinomial Input ) PRACTICAL\n",
    "13:12:52 Logistic Regression ( Multiclass Classification ) PRACTICAL\n",
    "13:29:07 Confusion Matrix\n",
    "13:51:22 Confusion Matrix ( Sensitivity, Precision, Recall and F1-Score )\n",
    "14:43:26 Naive Bayes & Conditional Probability\n",
    "15:05:33 Naive Bayes PRACTICAL\n",
    "15:19:10 Decision Tree ( Regression )\n",
    "15:41:47 Decision Tree Classification PRACTICAL\n",
    "16:04:03 Pre and Post Pruning ( Decision Tree )\n",
    "16:15:06 Decision Tree Regression\n",
    "16:28:41 K-Nearest Neighbours ( Classification)\n",
    "17:05:53 Support Vector Machines ( Classification )\n",
    "17:27:13 Support Vector Machines ( Classification ) PRACTICAL\n",
    "17:42:46 Support Vector Machines ( REGRESSION )\n",
    "17:57:58 Hyperparameter - Tuning, Model Parameter\n",
    "18:12:12 Hyperparameter Tuning PRACTICAL\n",
    "18:25:50 Cross-Validation ( In Machine Learning)\n",
    "18:34:09 K-Fold Cross-Validation Method\n",
    "18:37:10 Startified K-Fold Cross-Validation Method\n",
    "18:40:21 Leave-One-Out Cross-Validation Method \n",
    "18:42:28 Leave-P-Out Cross-Validation Method\n",
    "18:43:56 Cross-Validation PRACTICAL\n",
    "18:55:47 UNSUPERVISED LEARNING\n",
    "19:02:35 K-Means Clustering\n",
    "19:20:58 K-Means Clustering PRACTICAL\n",
    "20:02:04 Agglomerative Hierarchical PRACTICAL\n",
    "20:16:35 DBSCAN Clusturing Algorithm\n",
    "20:26:31 DBSCAN Clusturing Algorithm PRACTICAL\n",
    "20:36:29 SILHOUETTE SCORE\n",
    "20:54:15 Association Rule LEARNING\n",
    "21:11:15 Apriori Algorithm ( Association Rule LEARNING )\n",
    "21:26:18 Apriori Algorithm ( Association Rule LEARNING ) PRACTICAL\n",
    "21:52:19 Frequent Pattern Growth Algorithm ( Association Rule LEARNING )\n",
    "22:07:50 Frequent Pattern Growth Algorithm ( Association Rule LEARNING ) PRACTICAL\n",
    "22:16:57 Ensemble Learning\n",
    "22:24:29 Max Voting, Averaging and Weighted Average Voting\n",
    "22:34:08 Max Voting, Averaging and Weighted Average Voting ( CLASSIFICATION PRACTICAL )\n",
    "22:51:14 Max Voting, Averaging & Weighted Average Voting ( REGRESSION PRACTICAL)\n",
    "23:02:30 BAGGING ( BAGGING META-ESTIMATOR RANDOM FOREST )\n",
    "23:11:08 BAGGING ( BAGGING META-ESTIMATOR RANDOM FOREST ) PRACTICAL\n",
    "23:20:36 BAGGING ( BAGGING META-ESTIMATOR RANDOM FOREST ) REGRESSION PRACTICAL\n",
    "23:25:51 What is Deep Learning\n",
    "23:36:37 What is Neuron and Neural Networks\n",
    "23:43:01 Types of Deep Learning Networks\n",
    "23:44:41 Single Layer PERCEPTRON\n",
    "23:53:56 Working of PERCEPTRON\n",
    "24:04:40 Multilayer PERCEPTRON and Notation ( ANN )\n",
    "24:15:06 Forward and Backward Propagation\n",
    "24:39:10 Activation Function for Neural Networks\n",
    "24:51:25 LOSS FUNCTIONS \n",
    "25:15:08 OPTIMIZER in Neural Network\n",
    "25:23:26 CUSTOMER CHURN Prediction using ANN\n",
    "25:43:44 Improve The Performance of a Neural Network\n",
    "25:50:42 Identify Overfitting in Deep Learning ( EARLY STOPPING and REGULARISATION)\n",
    "26:14:25 BATCH NORMALIZATION\n",
    "26:23:06 DROPOUT LAYER\n",
    "26:38:13 VANISHING GRADIENT PROBLEM\n",
    "26:46:45 HYPERPARAMETER TUNING\n",
    "26:58:42 CONVOLUTIONAL Neural Network\n",
    "27:26:58 CONVOLUTIONAL Neural Network PRACTICAL\n",
    "\n",
    "--+--+--+--+--+END+--+--+--+--+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ae6409-6cc2-47fe-95ed-b3fca928efc7",
   "metadata": {},
   "source": [
    "#  Data Science Maths in-depth"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4094f04-fcb7-4c75-944f-e319c360a541",
   "metadata": {},
   "source": [
    "00:01:31  \n",
    "1 Introduction to Statistics✅\n",
    "   • Population & Sample✅\n",
    "   • Descriptive vs Inferential Statistics✅\n",
    "   • Basic Statistical Measures✅\n",
    "2 Measure of Central Tendency (Median, Mean, Mode)✅\n",
    "   • Measures of Variability✅\n",
    "   • Percentage, Percentiles, and Quartiles✅\n",
    "3 Probability✅\n",
    "   • Probability Distribution✅\n",
    "   • Normal Distribution✅\n",
    "   • Advanced Statistical Concepts✅\n",
    "4 Covariance and Correlation✅\n",
    "   • Central Limit Theorem✅\n",
    "   • Hypothesis Testing✅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b05cd9-b717-44f8-8467-24984c9f54c6",
   "metadata": {},
   "source": [
    "#  Machine Learning Complete"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0eface4-119f-445c-949f-fe7bf8a09d36",
   "metadata": {},
   "source": [
    "05:52:03 \n",
    "1 Introduction to Machine Learning (ML)✅\n",
    "2 Roadmap to Learning Machine Learning✅\n",
    "3 Types of Data and Variables in ML✅\n",
    "4 Data Cleaning:⚡️✅\n",
    "   • Identifying and Handling Missing Values✅\n",
    "   • One Hot Encoding & Dummy Variables✅\n",
    "   • Label Encoding✅\n",
    "   • Ordinal Encoding✅\n",
    "   • Outlier Detection and Removal✅& (clustering-4)\n",
    "   • Feature Scaling (Standardization and Normalization)✅\n",
    "   • Handling Duplicate Data✅\n",
    "   • Data Type Transformation✅\n",
    "5 Feature Selection Techniques:✅\n",
    "   • Backward Elimination (using mixed)✅\n",
    "   • Forward Elimination (using mixed)✅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761f79fc-0888-4c89-bfb5-cc8c164d44f6",
   "metadata": {},
   "source": [
    "# Supervised Learning in ML"
   ]
  },
  {
   "cell_type": "raw",
   "id": "006563e2-3138-49da-a192-d3fa8a978c2c",
   "metadata": {},
   "source": [
    "09:33:17 \n",
    "1 Train Test Split in Dataset⚡️✅\n",
    "2 Regression Analysis:✅\n",
    "   • Linear Regression Algorithm (Simple Linear)✅\n",
    "   • Multiple Linear Regression✅\n",
    "   • Polynomial Regression✅\n",
    "3 Cost Function in Regression✅\n",
    "4 R Squared Score & Adjusted R Squared in Regression Analysis✅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159a4596-cab7-4f18-b0f9-350c04914d7e",
   "metadata": {},
   "source": [
    "# Classification in ML"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07a38257-2151-4886-a22a-9ca4e57a65df",
   "metadata": {},
   "source": [
    "12:15:30 \n",
    "1 Classification⚡️ ❗️ \n",
    "2 Logistic Regression: ❗️\n",
    "   • Binary Classification (Practical)✅\n",
    "   • Binary Classification with Multiple Inputs (Practical)✅\n",
    "   • Binary Classification with Polynomial Inputs (Practical)✅\n",
    "   • Multiclass Classification (Practical)✅\n",
    "3 Confusion Matrix ❗️\n",
    "4 Imbalanced Dataset Handling✅\n",
    "5 Naive Bayes Algorithm ❗️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4304c34-23ce-4c58-b655-b5f28186b26a",
   "metadata": {},
   "source": [
    "# Non-Linear Supervised Algorithm in ML"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c292e7ef-5b76-4a13-b9fd-409f0dcc2fbc",
   "metadata": {},
   "source": [
    "15:18:11 \n",
    "1 Non-Linear Supervised Algorithms:✅\n",
    "   • Decision Tree (Classification)✅\n",
    "   • Decision Tree (Regression)✅\n",
    "   • K-Nearest Neighbors (Classification)✅\n",
    "   • Support Vector Machines (Classification)❗️\n",
    "   • Support Vector Machines ( REGRESSION )✅\n",
    "2 Hyperparameter Tuning⚡️ ❗️\n",
    "3 Cross-Validation⚡️✅\n",
    "4 Unsupervised Learning✅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191194c4-bb3a-463b-8fd4-f46c330de75e",
   "metadata": {},
   "source": [
    "# Clustering in ML"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d1e6aaa-9fe0-42b7-bf11-b0ecf341290f",
   "metadata": {},
   "source": [
    "19:01:23 \n",
    "1 Clustering⚡️✅\n",
    "2 K-means Clustering(Li)⚡️✅\n",
    "3 Hierarchical Clustering(Li)⚡️⚡️✅\n",
    "4 DBSCAN Clustering Algorithm(N-Li)⚡️✅\n",
    "5 Silhouette Score(for 2 & 3)✅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23579497-6830-494c-af2e-a2ee824b5fdc",
   "metadata": {},
   "source": [
    "# Association in ML"
   ]
  },
  {
   "cell_type": "raw",
   "id": "93a38612-e897-4985-a77b-28f9225d0d44",
   "metadata": {},
   "source": [
    "20:52:57 \n",
    "1 Association✅\n",
    "2 Association Rule Learning⚡️⚡️✅\n",
    "3 Apriori Algorithm⚡️⚡️✅\n",
    "4 Frequent Pattern Growth Algorithm/ FP Growth Algorithm⚡️⚡️✅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533ccf93-175a-4a3b-9a04-cf518db35813",
   "metadata": {},
   "source": [
    "# Ensemble Learning in ML"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52ac776e-e6a5-4d7e-a75d-3c817c72b8d1",
   "metadata": {},
   "source": [
    "22:15:34  \n",
    "1 Ensemble Learning⚡️⚡️⚡️✅\n",
    "2 Max Voting(Classification), Averaging & Weighted Average Voting(Regrassion)✅✅\n",
    "   • Practical Implementation for Regression⚡️⚡️⚡️✅\n",
    "   • Practical Implementation for Classification⚡️⚡️⚡️✅\n",
    "3 Bagging (with Bagging meta-estimator and Random forest)⚡️⚡️⚡️✅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8db767a-2a24-4e58-a3be-d41afe6fde99",
   "metadata": {},
   "source": [
    "# Deep Learning & AI Complete"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f172dd0-c5d3-45ba-8da9-c4038fc15519",
   "metadata": {},
   "source": [
    "23:25:50\n",
    "1 Deep Learning Overview:✅\n",
    "   • Introduction to Deep Learning✅\n",
    "   • Neurons, Neural Networks, and Types of Deep Learning Networks✅\n",
    "2 Perceptrons:✅\n",
    "   • Single Layer Perceptron✅\n",
    "   • Multilayer Perceptron (Artificial Neural Networks)⚡️⚡️⚡️✅\n",
    "3 Training Process:\n",
    "   • Forward Propagation and Backpropagation⚡️⚡️⚡️❗️\n",
    "   • Activation Functions⚡️⚡️⚡️❗️\n",
    "   • Loss Functions⚡️⚡️⚡️❗️\n",
    "   • Optimizers⚡️⚡️⚡️❗️\n",
    "4 Practical Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f91517-6b14-4596-a5fe-5507ae33ac2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
